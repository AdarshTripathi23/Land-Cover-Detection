{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlEd9QBXAzFi"
      },
      "source": [
        "# Land Cover Classification of RGB Satellite Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--POcu7uAzFo"
      },
      "source": [
        "**Aidan O'Keefe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dt2o_92AzFo"
      },
      "source": [
        "![LandCoverClasses.png](attachment:LandCoverClasses.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_F5ia0JAzFp"
      },
      "source": [
        "*Samples of each of the Land Cover Classes; from top left- Annual Crop, Forest, Herbaceous Vegetation, Highway, Industrial, Pasture, Permanent Crop, Residential, River, Sea or Lake*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7h36X1GAzFq"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbZu3cpDAzFq"
      },
      "source": [
        "A deep learning (neural network) land cover classification project using RGB satellite images (remote sensing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzPv2DOfAzFr"
      },
      "source": [
        "## Business Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBhgPaeLAzFs"
      },
      "source": [
        "The Nature Conservancy (TNC) is looking to help protect wildlife migration corridors from development/deforestation, but they canâ€™t be everywhere at once. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUK2l9jpAzFs"
      },
      "source": [
        "In order to help them find where to focus their efforts, we want to build Land Cover Classifier so that TNC can monitor deforestation using satellite images to observe if land starts changing from forest or vegetation to another class.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4W8NxqCAzFt"
      },
      "source": [
        "## Data Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMNBPbyVAzFt"
      },
      "source": [
        "For this project, I am using RGB satellite images from [EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification](https://zenodo.org/record/7711810#.ZCtEhOzMJQK)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf7DI1OdAzFt"
      },
      "source": [
        "This dataset contains 27,000 RGB Satellite Images across 10 classes: \n",
        "- Annual Crop\n",
        "- Forest\n",
        "- Herbaceous Vegetation\n",
        "- Highway\n",
        "- Industrial\n",
        "- Pasture\n",
        "- Permanent Crop\n",
        "- Residential\n",
        "- River\n",
        "- Sea or Lake <br><br>\n",
        "\n",
        "There are about 2,500 images per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eVs2TRVkAzFu"
      },
      "outputs": [],
      "source": [
        "#Import needed libraries\n",
        "import os, shutil\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "#Standard Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualizations\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
        "from keras import models, layers, optimizers, regularizers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.data.experimental import cardinality\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense # creates densely connected layer object\n",
        "from tensorflow.keras.layers import Flatten # takes 2D input and turns into 1D array\n",
        "from tensorflow.keras.layers import Conv2D # convolution layer\n",
        "from tensorflow.keras.layers import MaxPooling2D # max pooling layer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "#Transfer Learning\n",
        "from keras.applications import ResNet50, VGG19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aim-QQSxAzFv"
      },
      "source": [
        "### Import Data and Train/Validation/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVWgCGlwAzFv"
      },
      "outputs": [],
      "source": [
        "#Split Images into Train and Test folders using OS and Shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keitW2mkAzFw"
      },
      "outputs": [],
      "source": [
        "#List image path for all categories\n",
        "data_AnnualCrop = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/AnnualCrop'\n",
        "data_Forest = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Forest'\n",
        "data_HerbaceousVegetation = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/HerbaceousVegetation'\n",
        "data_Highway = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Highway'\n",
        "data_Industrial = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Industrial'\n",
        "data_Pasture = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Pasture'\n",
        "data_PermanentCrop = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/PermanentCrop'\n",
        "data_Residential = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Residential'\n",
        "data_River = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/River'\n",
        "data_SeaLake = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/SeaLake'\n",
        "\n",
        "\n",
        "new_dir = 'data/split/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKC0YUHUAzFw"
      },
      "outputs": [],
      "source": [
        "#Create objects that store all the relevant image names.\n",
        "imgs_AnnualCrop = [file for file in os.listdir(data_AnnualCrop) if file.endswith('.jpg')]\n",
        "imgs_Forest = [file for file in os.listdir(data_Forest) if file.endswith('.jpg')]\n",
        "imgs_HerbaceousVegetation = [file for file in os.listdir(data_HerbaceousVegetation) if file.endswith('.jpg')]\n",
        "imgs_Highway = [file for file in os.listdir(data_Highway) if file.endswith('.jpg')]\n",
        "imgs_Industrial = [file for file in os.listdir(data_Industrial) if file.endswith('.jpg')]\n",
        "imgs_Pasture = [file for file in os.listdir(data_Pasture) if file.endswith('.jpg')]\n",
        "imgs_PermanentCrop = [file for file in os.listdir(data_PermanentCrop) if file.endswith('.jpg')]\n",
        "imgs_Residential = [file for file in os.listdir(data_Residential) if file.endswith('.jpg')]\n",
        "imgs_River = [file for file in os.listdir(data_River) if file.endswith('.jpg')]\n",
        "imgs_SeaLake = [file for file in os.listdir(data_SeaLake) if file.endswith('.jpg')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9-GjhahAzFw"
      },
      "outputs": [],
      "source": [
        "# Make new split folder\n",
        "os.mkdir(new_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEi_iIG_AzFx"
      },
      "outputs": [],
      "source": [
        "#Set up the Train folder and subfolders\n",
        "train_folder = os.path.join(new_dir, 'train')\n",
        "train_AnnualCrop = os.path.join(train_folder, 'AnnualCrop')\n",
        "train_Forest = os.path.join(train_folder, 'Forest')\n",
        "train_HerbaceousVegetation = os.path.join(train_folder, 'HerbaceousVegetation')\n",
        "train_Highway = os.path.join(train_folder, 'Highway')\n",
        "train_Industrial = os.path.join(train_folder, 'Industrial')\n",
        "train_Pasture = os.path.join(train_folder, 'Pasture')\n",
        "train_PermanentCrop = os.path.join(train_folder, 'PermanentCrop')\n",
        "train_Residential = os.path.join(train_folder, 'Residential')\n",
        "train_River = os.path.join(train_folder, 'River')\n",
        "train_SeaLake = os.path.join(train_folder, 'SeaLake')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DEfz7j5AzFx"
      },
      "outputs": [],
      "source": [
        "#Set up the Test folder and subfolders\n",
        "test_folder = os.path.join(new_dir, 'test')\n",
        "test_AnnualCrop = os.path.join(test_folder, 'AnnualCrop')\n",
        "test_Forest = os.path.join(test_folder, 'Forest')\n",
        "test_HerbaceousVegetation = os.path.join(test_folder, 'HerbaceousVegetation')\n",
        "test_Highway = os.path.join(test_folder, 'Highway')\n",
        "test_Industrial = os.path.join(test_folder, 'Industrial')\n",
        "test_Pasture = os.path.join(test_folder, 'Pasture')\n",
        "test_PermanentCrop = os.path.join(test_folder, 'PermanentCrop')\n",
        "test_Residential = os.path.join(test_folder, 'Residential')\n",
        "test_River = os.path.join(test_folder, 'River')\n",
        "test_SeaLake = os.path.join(test_folder, 'SeaLake')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NUak31sAzFx"
      },
      "outputs": [],
      "source": [
        "# Make the Train directories(folders)\n",
        "os.mkdir(train_folder)\n",
        "os.mkdir(train_AnnualCrop)\n",
        "os.mkdir(train_Forest)\n",
        "os.mkdir(train_HerbaceousVegetation)\n",
        "os.mkdir(train_Highway)\n",
        "os.mkdir(train_Industrial)\n",
        "os.mkdir(train_Pasture)\n",
        "os.mkdir(train_PermanentCrop)\n",
        "os.mkdir(train_Residential)\n",
        "os.mkdir(train_River)\n",
        "os.mkdir(train_SeaLake)\n",
        "\n",
        "# Make the Test directories(folders)\n",
        "os.mkdir(test_folder)\n",
        "os.mkdir(test_AnnualCrop)\n",
        "os.mkdir(test_Forest)\n",
        "os.mkdir(test_HerbaceousVegetation)\n",
        "os.mkdir(test_Highway)\n",
        "os.mkdir(test_Industrial)\n",
        "os.mkdir(test_Pasture)\n",
        "os.mkdir(test_PermanentCrop)\n",
        "os.mkdir(test_Residential)\n",
        "os.mkdir(test_River)\n",
        "os.mkdir(test_SeaLake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDoSqY4OAzFy"
      },
      "outputs": [],
      "source": [
        "# Compile 80% of images into folders- Train\n",
        "imgs = imgs_AnnualCrop[:2400]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_AnnualCrop, img)\n",
        "    destination = os.path.join(train_AnnualCrop, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Forest[:2400]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Forest, img)\n",
        "    destination = os.path.join(train_Forest, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "\n",
        "imgs = imgs_HerbaceousVegetation[:2400]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_HerbaceousVegetation, img)\n",
        "    destination = os.path.join(train_HerbaceousVegetation, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Highway[:2000]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Highway, img)\n",
        "    destination = os.path.join(train_Highway, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Industrial[:2000]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Industrial, img)\n",
        "    destination = os.path.join(train_Industrial, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Pasture[:1600]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Pasture, img)\n",
        "    destination = os.path.join(train_Pasture, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_PermanentCrop[:2000]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_PermanentCrop, img)\n",
        "    destination = os.path.join(train_PermanentCrop, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Residential[:2400]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Residential, img)\n",
        "    destination = os.path.join(train_Residential, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_River[:2000]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_River, img)\n",
        "    destination = os.path.join(train_River, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_SeaLake[:2400]\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_SeaLake, img)\n",
        "    destination = os.path.join(train_SeaLake, img)\n",
        "    shutil.copyfile(origin, destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tJmAqS4AzFy"
      },
      "outputs": [],
      "source": [
        "# Compile other 20% of images into folders- Test\n",
        "imgs = imgs_AnnualCrop[2400:] #600\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_AnnualCrop, img)\n",
        "    destination = os.path.join(test_AnnualCrop, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Forest[2400:] #600\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Forest, img)\n",
        "    destination = os.path.join(test_Forest, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "\n",
        "imgs = imgs_HerbaceousVegetation[2400:] #600\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_HerbaceousVegetation, img)\n",
        "    destination = os.path.join(test_HerbaceousVegetation, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Highway[2000:] #500\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Highway, img)\n",
        "    destination = os.path.join(test_Highway, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Industrial[2000:] #500\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Industrial, img)\n",
        "    destination = os.path.join(test_Industrial, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Pasture[1600:] #400\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Pasture, img)\n",
        "    destination = os.path.join(test_Pasture, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_PermanentCrop[2000:] #500\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_PermanentCrop, img)\n",
        "    destination = os.path.join(test_PermanentCrop, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_Residential[2400:] #600\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_Residential, img)\n",
        "    destination = os.path.join(test_Residential, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_River[2000:] #500\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_River, img)\n",
        "    destination = os.path.join(test_River, img)\n",
        "    shutil.copyfile(origin, destination)\n",
        "    \n",
        "imgs = imgs_SeaLake[2400:] #600\n",
        "for img in imgs:\n",
        "    origin = os.path.join(data_SeaLake, img)\n",
        "    destination = os.path.join(test_SeaLake, img)\n",
        "    shutil.copyfile(origin, destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOkLuiV7AzF0",
        "outputId": "91bf55af-457f-4448-9fd2-a512fa3d037e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 18900 images belonging to 10 classes.\n",
            "Found 2700 images belonging to 10 classes.\n",
            "Found 5400 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_folder = 'data/split/train'\n",
        "test_folder = 'data/split/test'\n",
        "\n",
        "# Normalize images\n",
        "train_gen = ImageDataGenerator(rescale=1./255, validation_split = 0.125)\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
        "train_generator = train_gen.flow_from_directory(train_folder,\n",
        "                                                class_mode = 'categorical', \n",
        "                                                subset ='training', \n",
        "                                                batch_size=128,\n",
        "                                                shuffle=True,\n",
        "                                                seed=42)\n",
        "                                               \n",
        "val_generator= train_gen.flow_from_directory(train_folder,\n",
        "                                             class_mode= 'categorical',\n",
        "                                             subset = \"validation\",\n",
        "                                             batch_size=128,\n",
        "                                             shuffle=True,\n",
        "                                             seed=42)\n",
        "\n",
        "test_generator= test_gen.flow_from_directory(test_folder,\n",
        "                                              class_mode= 'categorical',\n",
        "                                              batch_size=128,\n",
        "                                              shuffle=False,\n",
        "                                              seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyAGupOSAzF1"
      },
      "outputs": [],
      "source": [
        "# create the data sets\n",
        "train_images, train_labels = next(train_generator)\n",
        "test_images, test_labels = next(test_generator)\n",
        "val_images, val_labels = next(val_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApQ1qbmuAzF1"
      },
      "source": [
        "### Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_xM--0hAzF1",
        "outputId": "2f2ec8f0-8739-4715-b813-5fe0ebd9748d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train ~ [(0, 2100), (1, 2100), (2, 2100), (3, 1750), (4, 1750), (5, 1400), (6, 1750), (7, 2100), (8, 1750), (9, 2100)]\n",
            "Validation ~ [(0, 300), (1, 300), (2, 300), (3, 250), (4, 250), (5, 200), (6, 250), (7, 300), (8, 250), (9, 300)]\n",
            "Test ~ [(0, 600), (1, 600), (2, 600), (3, 500), (4, 500), (5, 400), (6, 500), (7, 600), (8, 500), (9, 600)]\n"
          ]
        }
      ],
      "source": [
        "#Confirm class balance for train and test\n",
        "train_classes = train_generator.classes\n",
        "val_classes = val_generator.classes\n",
        "test_classes = test_generator.classes\n",
        "\n",
        "#Look at image distribution by class across train, test, and validation sets.\n",
        "train_class, train_count = np.unique(train_classes, return_counts=True)\n",
        "val_class, val_count = np.unique(val_classes, return_counts=True)\n",
        "test_class, test_count = np.unique(test_classes, return_counts=True)\n",
        "\n",
        "print('Train ~ {}'.format(list(zip(train_class, train_count))))\n",
        "print('Validation ~ {}'.format(list(zip(val_class, val_count))))\n",
        "print('Test ~ {}'.format(list(zip(test_class, test_count))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "zF7KS8FIAzF2",
        "outputId": "25fd9b87-d1a8-43e5-86c8-5f224b856d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n",
            "Validation: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n",
            "Train: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n"
          ]
        }
      ],
      "source": [
        "#Checking the classes in our train data \n",
        "train_class_names = train_generator.class_indices\n",
        "print('Train:', train_class_names)\n",
        "\n",
        "#Checking the classes in our validation data\n",
        "val_class_names = val_generator.class_indices\n",
        "print('Validation:', val_class_names)\n",
        "\n",
        "#Checking the classes in our test data\n",
        "test_class_names = test_generator.class_indices\n",
        "print('Train:', test_class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dukgFJwrAzF2",
        "outputId": "ed55f809-bdef-410e-c3cc-25a159186d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train\n",
            "(128, 256, 256, 3)\n",
            "(128, 10)\n",
            "Validation\n",
            "(128, 256, 256, 3)\n",
            "(128, 10)\n",
            "Test\n",
            "(128, 256, 256, 3)\n",
            "(128, 10)\n"
          ]
        }
      ],
      "source": [
        "# Preview the shape of both the images and labels for both the train, validation, and test sets (8 objects total)\n",
        "print(\"Train\")\n",
        "print(np.shape(train_images))\n",
        "print(np.shape(train_labels))\n",
        "print(\"Validation\")\n",
        "print(np.shape(val_images))\n",
        "print(np.shape(val_labels))\n",
        "print(\"Test\")\n",
        "print(np.shape(test_images))\n",
        "print(np.shape(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lwc91RwOAzF2",
        "outputId": "6e7cba57-4d1c-41fe-c611-b7dc608b55c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=256x256 at 0x7FF692526610>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview a train data image\n",
        "print(train_labels[0])\n",
        "array_to_img(train_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IAaxbXwAzF2",
        "outputId": "67d3dcc8-04ec-4b11-82da-d1806be9b83b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=256x256 at 0x7FF689F5DA00>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview a test data image\n",
        "print(test_labels[0])\n",
        "array_to_img(test_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rE7bNT8AzF3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHuwAxNVAzF3"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwnuxVWZAzF3"
      },
      "source": [
        "### Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIdfid5hAzF3"
      },
      "source": [
        "For our baseline model, we will create a simple Sequential Neural Network with one Convolutional Layer, one Max Pooling Layer, and one Dense Layer (not including our output layer). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUFKYIPmAzF3",
        "outputId": "dfffde53-f665-4606-e543-f3c6538683ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 516128)            0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                33032256  \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 33,033,802\n",
            "Trainable params: 33,033,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "baseline_model = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Convolution\n",
        "baseline_model.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3)))\n",
        "\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "baseline_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- connect all nodes with dense layer\n",
        "baseline_model.add(Flatten())\n",
        "baseline_model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "baseline_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "baseline_model.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "baseline_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FB11RqMEAzF3",
        "outputId": "3268cf17-8f4a-4c75-cd95-098475c1c0bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 327s 2s/step - loss: 3.3877 - accuracy: 0.2939 - val_loss: 1.6197 - val_accuracy: 0.3700\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 353s 2s/step - loss: 1.5218 - accuracy: 0.4223 - val_loss: 1.4075 - val_accuracy: 0.4696\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 375s 3s/step - loss: 1.2251 - accuracy: 0.5588 - val_loss: 1.0713 - val_accuracy: 0.6007\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 310s 2s/step - loss: 1.0015 - accuracy: 0.6423 - val_loss: 1.0096 - val_accuracy: 0.6422\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 296s 2s/step - loss: 0.8978 - accuracy: 0.6808 - val_loss: 0.9568 - val_accuracy: 0.6426\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 296s 2s/step - loss: 0.8389 - accuracy: 0.7003 - val_loss: 0.9141 - val_accuracy: 0.6644\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 298s 2s/step - loss: 0.7665 - accuracy: 0.7302 - val_loss: 0.9494 - val_accuracy: 0.6615\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 296s 2s/step - loss: 0.7125 - accuracy: 0.7523 - val_loss: 0.9027 - val_accuracy: 0.6656\n",
            "Epoch 9/20\n",
            "148/148 [==============================] - 298s 2s/step - loss: 0.6604 - accuracy: 0.7748 - val_loss: 0.8528 - val_accuracy: 0.6907\n",
            "Epoch 10/20\n",
            "148/148 [==============================] - 323s 2s/step - loss: 0.5992 - accuracy: 0.8001 - val_loss: 0.8202 - val_accuracy: 0.7204\n",
            "Epoch 11/20\n",
            "148/148 [==============================] - 306s 2s/step - loss: 0.5203 - accuracy: 0.8258 - val_loss: 0.8082 - val_accuracy: 0.7163\n",
            "Epoch 12/20\n",
            "148/148 [==============================] - 328s 2s/step - loss: 0.4612 - accuracy: 0.8526 - val_loss: 0.8119 - val_accuracy: 0.7174\n",
            "Epoch 13/20\n",
            "148/148 [==============================] - 329s 2s/step - loss: 0.4023 - accuracy: 0.8755 - val_loss: 0.8557 - val_accuracy: 0.7115\n",
            "Epoch 14/20\n",
            "148/148 [==============================] - 309s 2s/step - loss: 0.3558 - accuracy: 0.8920 - val_loss: 0.8262 - val_accuracy: 0.7237\n",
            "Epoch 15/20\n",
            "148/148 [==============================] - 306s 2s/step - loss: 0.3132 - accuracy: 0.9081 - val_loss: 0.8719 - val_accuracy: 0.7167\n",
            "Epoch 16/20\n",
            "148/148 [==============================] - 314s 2s/step - loss: 0.2626 - accuracy: 0.9238 - val_loss: 0.8958 - val_accuracy: 0.7263\n",
            "Epoch 17/20\n",
            "148/148 [==============================] - 316s 2s/step - loss: 0.2401 - accuracy: 0.9327 - val_loss: 0.9385 - val_accuracy: 0.7033\n",
            "Epoch 18/20\n",
            "148/148 [==============================] - 320s 2s/step - loss: 0.1822 - accuracy: 0.9534 - val_loss: 0.9168 - val_accuracy: 0.7281\n",
            "Epoch 19/20\n",
            "148/148 [==============================] - 325s 2s/step - loss: 0.1773 - accuracy: 0.9526 - val_loss: 1.0057 - val_accuracy: 0.7167\n",
            "Epoch 20/20\n",
            "148/148 [==============================] - 317s 2s/step - loss: 0.1472 - accuracy: 0.9641 - val_loss: 1.0582 - val_accuracy: 0.7226\n"
          ]
        }
      ],
      "source": [
        "#Fit the model \n",
        "baseline_history = baseline_model.fit(train_generator, \n",
        "                                      epochs = 20, \n",
        "                                      batch_size= 128, \n",
        "                                      verbose = 1, \n",
        "                                      validation_data = val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEkMfN8uAzF4",
        "outputId": "767222a2-164b-4e56-9f57-dff888323d38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 25s 585ms/step - loss: 1.0459 - accuracy: 0.7411\n",
            "Test loss:  1.0459473133087158\n",
            "Test accuracy:  0.7411110997200012\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = baseline_model.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY32LY7VAzF4"
      },
      "source": [
        "It looks like after 20 Epochs our baseline model overfit with a 96.4% train accuracy and a 74.1% test accuracy. In the future, we will also want to use Early Stopping to prevent the model from continuing to overfit. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEEys1tgAzF4"
      },
      "source": [
        "### First Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHrqIvBAAzF4"
      },
      "source": [
        "Let's make our CNN \"deeper\" and add additonal convolution and max pooling layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2s-Cl4jAzF4",
        "outputId": "84846d79-7e08-49bd-afa8-7dde054410ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 123008)            0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                7872576   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 7,883,370\n",
            "Trainable params: 7,883,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_one = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_one.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3)))\n",
        "\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_one.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_one.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_one.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- connect all nodes with dense layer\n",
        "model_one.add(Flatten())\n",
        "model_one.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_one.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_one.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_one.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4lN_Dk5AzF5"
      },
      "source": [
        "Let's also add a stopping criteria as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlsLQQfbAzF5",
        "outputId": "ce69510c-4020-4911-ebf6-2143e446ae58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 444s 3s/step - loss: 1.5299 - accuracy: 0.4476 - val_loss: 1.1410 - val_accuracy: 0.5926\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 452s 3s/step - loss: 1.0054 - accuracy: 0.6348 - val_loss: 0.9596 - val_accuracy: 0.6463\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 449s 3s/step - loss: 0.8038 - accuracy: 0.7134 - val_loss: 0.8036 - val_accuracy: 0.6993\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 490s 3s/step - loss: 0.6379 - accuracy: 0.7755 - val_loss: 0.7442 - val_accuracy: 0.7374\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 553s 4s/step - loss: 0.5075 - accuracy: 0.8248 - val_loss: 0.6600 - val_accuracy: 0.7711\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 451s 3s/step - loss: 0.4197 - accuracy: 0.8556 - val_loss: 0.7485 - val_accuracy: 0.7367\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 440s 3s/step - loss: 0.3318 - accuracy: 0.8915 - val_loss: 0.6621 - val_accuracy: 0.7807\n",
            "Epoch 00007: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_one_history = model_one.fit(train_generator, \n",
        "                                  epochs= 20, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LzoxWKnAzF5",
        "outputId": "b7465a10-c586-4f02-b852-4bc39a441682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 36s 827ms/step - loss: 0.6744 - accuracy: 0.7857\n",
            "Test loss:  0.6743987798690796\n",
            "Test accuracy:  0.7857407331466675\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_one.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjPqzWWHAzF5"
      },
      "source": [
        "Making our model deeper and adding early stopping seemed to help; our model stopped after 7 Epochs once validation loss stopped decreasing. Our model is still overfit but less so with a 89.2% Train accuracy and a 78.6% Test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMEJjS_3AzF5"
      },
      "outputs": [],
      "source": [
        "# # probability for each class\n",
        "# y_proba = model_images.predict(x_test)\n",
        "# y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lseOTCtkAzF6"
      },
      "outputs": [],
      "source": [
        "# # argmax axis = -1 gets the column index of maximum probability for each row.\n",
        "# # column index corresponds to digit classes (numbers 0 -9)\n",
        "# predicted = np.argmax(y_proba, axis=-1)\n",
        "# predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcJb_X3aAzF6"
      },
      "outputs": [],
      "source": [
        "# #View confusion matrix of test predictions\n",
        "# cm_digits = confusion_matrix(y_test, predicted)\n",
        "# disp = ConfusionMatrixDisplay(\n",
        "#     confusion_matrix=cm_digits)\n",
        "\n",
        "# disp.plot(cmap=plt.cm.Blues)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iy7olaYrAzF6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GcPQn-HAzF6"
      },
      "source": [
        "### Adding Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C0yAQYzAzF6"
      },
      "source": [
        "To help with the consistent overfitting, let's try out a few regularization techniques: L1, L2, and Dropout Layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgok0pFhAzF6"
      },
      "source": [
        "#### Model 2- L1 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J54q8WtwAzF7",
        "outputId": "0acff9d5-99ff-46eb-cda3-049be830210e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 123008)            0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 64)                7872576   \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 7,883,370\n",
            "Trainable params: 7,883,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_l1 = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_l1.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3),\n",
        "                     kernel_regularizer=regularizers.l1(0.005)))\n",
        "\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_l1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_l1.add(layers.Conv2D(32, (3, 3), \n",
        "                            activation='relu', \n",
        "                            kernel_regularizer=regularizers.l1(0.005)))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_l1.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- connect all nodes with dense layer\n",
        "model_l1.add(Flatten())\n",
        "model_l1.add(Dense(64, \n",
        "                    activation='relu', \n",
        "                    kernel_regularizer=regularizers.l1(0.005)))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_l1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_l1.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_l1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THU1ZdHMAzF7",
        "outputId": "69c2f0c8-f9b8-492f-dcec-dfee4ef5b093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 442s 3s/step - loss: 13.5989 - accuracy: 0.1928 - val_loss: 7.3832 - val_accuracy: 0.2019\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 432s 3s/step - loss: 7.1454 - accuracy: 0.2334 - val_loss: 6.8890 - val_accuracy: 0.2422\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 433s 3s/step - loss: 6.8911 - accuracy: 0.2394 - val_loss: 6.7559 - val_accuracy: 0.2585\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 440s 3s/step - loss: 6.7881 - accuracy: 0.2473 - val_loss: 6.7858 - val_accuracy: 0.2333\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 426s 3s/step - loss: 6.7365 - accuracy: 0.2517 - val_loss: 6.7388 - val_accuracy: 0.2959\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 431s 3s/step - loss: 6.7060 - accuracy: 0.2513 - val_loss: 6.6780 - val_accuracy: 0.2541\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 428s 3s/step - loss: 6.6548 - accuracy: 0.2603 - val_loss: 6.6618 - val_accuracy: 0.2311\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 427s 3s/step - loss: 6.6269 - accuracy: 0.2657 - val_loss: 6.5992 - val_accuracy: 0.2730\n",
            "Epoch 9/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 6.6214 - accuracy: 0.2676 - val_loss: 6.5711 - val_accuracy: 0.2615\n",
            "Epoch 10/20\n",
            "148/148 [==============================] - 431s 3s/step - loss: 6.5939 - accuracy: 0.2741 - val_loss: 6.7074 - val_accuracy: 0.2441\n",
            "Epoch 11/20\n",
            "148/148 [==============================] - 428s 3s/step - loss: 6.5794 - accuracy: 0.2789 - val_loss: 6.5057 - val_accuracy: 0.2648\n",
            "Epoch 12/20\n",
            "148/148 [==============================] - 436s 3s/step - loss: 6.5395 - accuracy: 0.2841 - val_loss: 6.5433 - val_accuracy: 0.3022\n",
            "Epoch 13/20\n",
            "148/148 [==============================] - 437s 3s/step - loss: 6.5210 - accuracy: 0.2904 - val_loss: 6.6076 - val_accuracy: 0.2556\n",
            "Epoch 00013: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_l1_history = model_l1.fit(train_generator, \n",
        "                                  epochs= 20, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAPsNJOuAzF7",
        "outputId": "10a66788-32c8-4dd8-a81a-65b58b9ff0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 33s 768ms/step - loss: 6.5977 - accuracy: 0.2669\n",
            "Test loss:  6.597667217254639\n",
            "Test accuracy:  0.26685184240341187\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_l1.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bVIxnMTAzF7"
      },
      "source": [
        "#### Model 3- L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgTlZQhOAzF7",
        "outputId": "6bab477a-8fa0-433c-cdcb-26a417b4604a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 123008)            0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 64)                7872576   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 7,883,370\n",
            "Trainable params: 7,883,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_l2 = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_l2.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3),\n",
        "                     kernel_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_l2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_l2.add(layers.Conv2D(32, (3, 3), \n",
        "                            activation='relu', \n",
        "                            kernel_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_l2.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- connect all nodes with dense layer\n",
        "model_l2.add(Flatten())\n",
        "model_l2.add(Dense(64, \n",
        "                    activation='relu', \n",
        "                    kernel_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_l2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_l2.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_l2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSZCxTV1AzF8",
        "outputId": "07979bac-6e35-4474-ad42-1fdda1e8d43d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 432s 3s/step - loss: 2.1379 - accuracy: 0.3422 - val_loss: 1.9591 - val_accuracy: 0.3393\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 430s 3s/step - loss: 1.6320 - accuracy: 0.4792 - val_loss: 1.5435 - val_accuracy: 0.4852\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 430s 3s/step - loss: 1.4293 - accuracy: 0.5686 - val_loss: 1.3838 - val_accuracy: 0.5859\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 431s 3s/step - loss: 1.3499 - accuracy: 0.5898 - val_loss: 1.3529 - val_accuracy: 0.5700\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 437s 3s/step - loss: 1.2759 - accuracy: 0.6182 - val_loss: 1.2808 - val_accuracy: 0.6100\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 430s 3s/step - loss: 1.2131 - accuracy: 0.6368 - val_loss: 1.1424 - val_accuracy: 0.6789\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 1.1644 - accuracy: 0.6528 - val_loss: 1.1429 - val_accuracy: 0.6578\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 432s 3s/step - loss: 1.1263 - accuracy: 0.6613 - val_loss: 1.1465 - val_accuracy: 0.6585\n",
            "Epoch 00008: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_l2_history = model_l2.fit(train_generator, \n",
        "                                  epochs= 20, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGslLDKFAzF8",
        "outputId": "d161add8-e0b2-459d-a715-d2179f587ac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 35s 806ms/step - loss: 1.1507 - accuracy: 0.6563\n",
            "Test loss:  1.150733232498169\n",
            "Test accuracy:  0.6562963128089905\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_l2.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKZ_oj7EAzF8"
      },
      "source": [
        "#### Model 4- Dropout Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phuuEiQLAzF8",
        "outputId": "d6bc0f1d-30a8-47be-cba7-3b4dc7eca3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout_10 (Dropout)         (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 123008)            0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 64)                7872576   \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 7,883,370\n",
            "Trainable params: 7,883,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_dropout = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Dropout\n",
        "model_dropout.add(layers.Dropout(0.2, input_shape= (256, 256, 3)))\n",
        "\n",
        "#Convolution Layer\n",
        "model_dropout.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu'))\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_dropout.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_dropout.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_dropout.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_dropout.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model_dropout.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 4- connect all nodes with dense layer\n",
        "model_dropout.add(Flatten())\n",
        "model_dropout.add(Dense(64, activation='relu'))\n",
        "\n",
        "model_dropout.add(layers.Dropout(0.2))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_dropout.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_dropout.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_dropout.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soMD5CkSAzF8",
        "outputId": "6f9eaf3e-7cab-4ecf-8d18-afc423d7eba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 517s 3s/step - loss: 2.4970 - accuracy: 0.1553 - val_loss: 2.1980 - val_accuracy: 0.1674\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 514s 3s/step - loss: 1.9059 - accuracy: 0.2441 - val_loss: 2.0253 - val_accuracy: 0.2404\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 513s 3s/step - loss: 1.7884 - accuracy: 0.2856 - val_loss: 1.8434 - val_accuracy: 0.3511\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 514s 3s/step - loss: 1.7333 - accuracy: 0.3106 - val_loss: 1.7482 - val_accuracy: 0.3663\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 512s 3s/step - loss: 1.6867 - accuracy: 0.3358 - val_loss: 1.7402 - val_accuracy: 0.3463\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 513s 3s/step - loss: 1.6566 - accuracy: 0.3614 - val_loss: 1.6861 - val_accuracy: 0.3889\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 519s 4s/step - loss: 1.5778 - accuracy: 0.4080 - val_loss: 1.8090 - val_accuracy: 0.3348\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 512s 3s/step - loss: 1.5274 - accuracy: 0.4299 - val_loss: 1.7019 - val_accuracy: 0.3752\n",
            "Epoch 00008: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_dropout_history = model_dropout.fit(train_generator, \n",
        "                                  epochs= 20, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEP2QxsmAzF9",
        "outputId": "d1b03292-bb82-441b-c09d-c35e9e7e46ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 33s 774ms/step - loss: 1.7064 - accuracy: 0.3637\n",
            "Test loss:  1.7064480781555176\n",
            "Test accuracy:  0.3637036979198456\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_dropout.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0WBYcvTAzF9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNMP0TFiAzF9"
      },
      "source": [
        "#### Model 5- Dropout and L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZuooflMAzF9",
        "outputId": "1d375878-a12b-441c-e3da-1438c685cef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 123008)            0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 32)                3936288   \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 3,949,194\n",
            "Trainable params: 3,949,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_five = Sequential()\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_five.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3),\n",
        "                     kernel_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_five.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_five.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_five.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_five.add(layers.MaxPooling2D((2, 2)))\n",
        "model_five.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 4- connect all nodes with dense layer\n",
        "model_five.add(Flatten())\n",
        "model_five.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "#Layer 5\n",
        "model_five.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_five.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_five.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_five.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbUzRiT9AzF9",
        "outputId": "252d7e32-cbc4-475c-a28d-70589f062b61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 490s 3s/step - loss: 2.4675 - accuracy: 0.1976 - val_loss: 1.9717 - val_accuracy: 0.3196\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 490s 3s/step - loss: 1.8828 - accuracy: 0.3471 - val_loss: 1.7990 - val_accuracy: 0.3978\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 490s 3s/step - loss: 1.7338 - accuracy: 0.4206 - val_loss: 1.6767 - val_accuracy: 0.4407\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 491s 3s/step - loss: 1.6063 - accuracy: 0.4655 - val_loss: 1.5370 - val_accuracy: 0.5059\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 490s 3s/step - loss: 1.5095 - accuracy: 0.5031 - val_loss: 1.4821 - val_accuracy: 0.5026\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 502s 3s/step - loss: 1.4447 - accuracy: 0.5267 - val_loss: 1.4239 - val_accuracy: 0.5456\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 490s 3s/step - loss: 1.4236 - accuracy: 0.5341 - val_loss: 1.4637 - val_accuracy: 0.5156\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 490s 3s/step - loss: 1.3587 - accuracy: 0.5542 - val_loss: 1.4379 - val_accuracy: 0.5337\n",
            "Epoch 00008: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_five_history = model_five.fit(train_generator, \n",
        "                                  epochs= 20, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdrV3QuaAzF9",
        "outputId": "4d2955b5-8cd5-4afc-84fc-190e430b6d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 32s 754ms/step - loss: 1.4017 - accuracy: 0.5459\n",
            "Test loss:  1.4017235040664673\n",
            "Test accuracy:  0.5459259152412415\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_five.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnc8jps8AzF-"
      },
      "source": [
        "### Model 6- Increasing initial Convolution Layer's Filter and Kernal size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt7XW51yAzF-"
      },
      "source": [
        "Also arranged Dense layers in decreasing order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW6A4r8HAzF-",
        "outputId": "7affe412-da5d-4892-f2b7-fd8b364a7899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 252, 252, 64)      4864      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 126, 126, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 124, 124, 32)      18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 123008)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                7872576   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 7,898,314\n",
            "Trainable params: 7,898,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_six = Sequential()\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_six.add(Conv2D(filters=64,\n",
        "                          kernel_size=(5, 5),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3)))\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_six.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_six.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_six.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- connect all nodes with dense layer\n",
        "model_six.add(Flatten())\n",
        "model_six.add(Dense(64, activation='relu'))\n",
        "\n",
        "#Layer 5\n",
        "model_six.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_six.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_six.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_six.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-B_kyOaAzF-",
        "outputId": "1692e907-81ed-4ddb-e337-d7a4136efb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 1051s 7s/step - loss: 2.0885 - accuracy: 0.2260 - val_loss: 1.8681 - val_accuracy: 0.2626\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 1014s 7s/step - loss: 1.7389 - accuracy: 0.3028 - val_loss: 1.6575 - val_accuracy: 0.3219\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 996s 7s/step - loss: 1.5863 - accuracy: 0.3687 - val_loss: 1.5469 - val_accuracy: 0.4181\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 974s 7s/step - loss: 1.5005 - accuracy: 0.4251 - val_loss: 1.4903 - val_accuracy: 0.4241\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 955s 6s/step - loss: 1.4163 - accuracy: 0.4676 - val_loss: 1.4474 - val_accuracy: 0.4526\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 957s 6s/step - loss: 1.3258 - accuracy: 0.5107 - val_loss: 1.4705 - val_accuracy: 0.4389\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 945s 6s/step - loss: 1.2367 - accuracy: 0.5442 - val_loss: 1.3537 - val_accuracy: 0.4919\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 963s 7s/step - loss: 1.1416 - accuracy: 0.5841 - val_loss: 1.3715 - val_accuracy: 0.5048\n",
            "Epoch 9/20\n",
            "148/148 [==============================] - 956s 6s/step - loss: 1.0401 - accuracy: 0.6261 - val_loss: 1.2836 - val_accuracy: 0.5393\n",
            "Epoch 10/20\n",
            "148/148 [==============================] - 949s 6s/step - loss: 0.9935 - accuracy: 0.6438 - val_loss: 1.3660 - val_accuracy: 0.5148\n",
            "Epoch 11/20\n",
            "148/148 [==============================] - 960s 6s/step - loss: 0.9111 - accuracy: 0.6721 - val_loss: 1.4051 - val_accuracy: 0.5300\n",
            "Epoch 00011: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_six_history = model_six.fit(train_generator, \n",
        "                                  epochs= 20, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taXwk4xNAzF-",
        "outputId": "7b2addba-80c5-4686-ed5a-04378cf57d4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 59s 1s/step - loss: 1.3475 - accuracy: 0.5319\n",
            "Test loss:  1.3474699258804321\n",
            "Test accuracy:  0.5318518280982971\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_six.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8YBxfCnAzF-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWLDU44_AzF-"
      },
      "source": [
        "### Model 7- Add Dense(128) Layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T2C5Go9AzF_",
        "outputId": "370250be-a404-4188-c8b3-47af16996c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 123008)            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               15745152  \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 15,765,962\n",
            "Trainable params: 15,765,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_seven = Sequential()\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_seven.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3)))\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_seven.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_seven.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_seven.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- connect all nodes with dense layer\n",
        "model_seven.add(Flatten())\n",
        "model_seven.add(Dense(128, activation='relu'))                \n",
        "                \n",
        "# Layer 5- dense layer                \n",
        "model_seven.add(Dense(64, activation='relu'))\n",
        "                \n",
        "# Layer 6- dense layer  \n",
        "model_seven.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_seven.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_seven.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_seven.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnA0ed59AzF_",
        "outputId": "9ec7e7ae-8432-4fe4-f60a-b4a3a878369f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 431s 3s/step - loss: 1.7042 - accuracy: 0.3772 - val_loss: 1.3390 - val_accuracy: 0.5141\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 1.2923 - accuracy: 0.5213 - val_loss: 1.2157 - val_accuracy: 0.5633\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 1.1309 - accuracy: 0.5794 - val_loss: 1.1131 - val_accuracy: 0.5915\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 427s 3s/step - loss: 1.0286 - accuracy: 0.6232 - val_loss: 1.0793 - val_accuracy: 0.6115\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 0.9325 - accuracy: 0.6661 - val_loss: 0.9119 - val_accuracy: 0.6815\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 0.7214 - accuracy: 0.7420 - val_loss: 0.7592 - val_accuracy: 0.7244\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 433s 3s/step - loss: 0.5805 - accuracy: 0.7905 - val_loss: 0.7856 - val_accuracy: 0.7289\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 0.4392 - accuracy: 0.8489 - val_loss: 0.7429 - val_accuracy: 0.7504\n",
            "Epoch 9/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 0.3402 - accuracy: 0.8849 - val_loss: 0.8058 - val_accuracy: 0.7430\n",
            "Epoch 10/20\n",
            "148/148 [==============================] - 431s 3s/step - loss: 0.2509 - accuracy: 0.9196 - val_loss: 0.7860 - val_accuracy: 0.7596\n",
            "Epoch 00010: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_seven_history = model_seven.fit(train_generator, \n",
        "                                  epochs= 20, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZasdjbdAzF_",
        "outputId": "c8a061e0-de8b-478a-9e5a-6be2cd6503e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 33s 758ms/step - loss: 0.7563 - accuracy: 0.7769\n",
            "Test loss:  0.7563361525535583\n",
            "Test accuracy:  0.7768518328666687\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_seven.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyMrfSq9AzGA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja3QvzByAzGA"
      },
      "source": [
        "### Model 8- Deeper CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrjvgQJEAzGA"
      },
      "source": [
        "Adding another Convolutional with Max Pooling Layer.  Also changing our EarlyStopping callback to monitor validation accuracy instead of validation loss. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W03EaByCAzGA",
        "outputId": "df52b576-bd20-433b-ca0b-d31919b51a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 60, 60, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 28800)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                1843264   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,867,466\n",
            "Trainable params: 1,867,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_eight = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_eight.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3)))\n",
        "\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_eight.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_eight.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_eight.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- another convolution layer \n",
        "model_eight.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 5- another max pool layer\n",
        "model_eight.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 6- connect all nodes with dense layer\n",
        "model_eight.add(Flatten())\n",
        "model_eight.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Layer 7- dense layer\n",
        "model_eight.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_eight.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_eight.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_eight.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-_f1rzHAzGA",
        "outputId": "d7f2d6db-d4a8-46e2-fcdb-6b5e839ef4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 527s 4s/step - loss: 1.6420 - accuracy: 0.3805 - val_loss: 1.2893 - val_accuracy: 0.5274\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 574s 4s/step - loss: 1.1483 - accuracy: 0.5761 - val_loss: 1.0552 - val_accuracy: 0.6193\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 586s 4s/step - loss: 0.9700 - accuracy: 0.6397 - val_loss: 0.8785 - val_accuracy: 0.6837\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 501s 3s/step - loss: 0.7638 - accuracy: 0.7220 - val_loss: 0.8687 - val_accuracy: 0.6863\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 478s 3s/step - loss: 0.6472 - accuracy: 0.7644 - val_loss: 0.7288 - val_accuracy: 0.7363\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 568s 4s/step - loss: 0.5564 - accuracy: 0.7957 - val_loss: 0.6097 - val_accuracy: 0.7800\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 547s 4s/step - loss: 0.4814 - accuracy: 0.8262 - val_loss: 0.6907 - val_accuracy: 0.7600\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 508s 3s/step - loss: 0.4337 - accuracy: 0.8431 - val_loss: 0.5844 - val_accuracy: 0.7889\n",
            "Epoch 9/20\n",
            "148/148 [==============================] - 548s 4s/step - loss: 0.3971 - accuracy: 0.8590 - val_loss: 0.6085 - val_accuracy: 0.7859\n",
            "Epoch 10/20\n",
            "148/148 [==============================] - 503s 3s/step - loss: 0.3338 - accuracy: 0.8838 - val_loss: 0.6405 - val_accuracy: 0.7837\n",
            "Epoch 00010: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_eight_history = model_eight.fit(train_generator, \n",
        "                                  epochs= 20, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wveApKWIAzGA",
        "outputId": "86ad5322-70a1-461a-9b22-527fc93059a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 36s 846ms/step - loss: 0.6190 - accuracy: 0.7902\n",
            "Test loss:  0.619040846824646\n",
            "Test accuracy:  0.7901852130889893\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_eight.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ8sT6SrAzGB"
      },
      "source": [
        "### Model 9- Deeper CNN with 0.5 Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9iEv6d0AzGB"
      },
      "source": [
        "Adding two 0.5 Dropout Layers after two Dense layers to help address overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYnaZOQ_AzGB",
        "outputId": "ce0f275a-7631-46af-bd0d-def4734becd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 60, 60, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 28800)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                1843264   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 1,865,066\n",
            "Trainable params: 1,865,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_nine = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_nine.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3)))\n",
        "\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_nine.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_nine.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_nine.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- another convolution layer \n",
        "model_nine.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 5- another max pool layer\n",
        "model_nine.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 6- connect all nodes with dense layer\n",
        "model_nine.add(Flatten())\n",
        "model_nine.add(Dense(64, activation='relu'))\n",
        "model_nine.add(layers.Dropout(0.5))\n",
        "\n",
        "# Layer 7- dense layer\n",
        "model_nine.add(Dense(32, activation='relu'))\n",
        "model_nine.add(layers.Dropout(0.5))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_nine.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_nine.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_nine.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAHmuIuMAzGB",
        "outputId": "3e975c93-539d-4bd7-fd51-3be3a8a3474d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 515s 3s/step - loss: 2.0381 - accuracy: 0.2160 - val_loss: 1.6584 - val_accuracy: 0.3137\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 539s 4s/step - loss: 1.7128 - accuracy: 0.3208 - val_loss: 1.4542 - val_accuracy: 0.4937\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 482s 3s/step - loss: 1.5734 - accuracy: 0.3838 - val_loss: 1.3543 - val_accuracy: 0.5067\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 475s 3s/step - loss: 1.4843 - accuracy: 0.4311 - val_loss: 1.2336 - val_accuracy: 0.5541\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 475s 3s/step - loss: 1.4023 - accuracy: 0.4672 - val_loss: 1.1401 - val_accuracy: 0.5885\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 477s 3s/step - loss: 1.3401 - accuracy: 0.4953 - val_loss: 1.0915 - val_accuracy: 0.6515\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 538s 4s/step - loss: 1.2818 - accuracy: 0.5334 - val_loss: 1.0660 - val_accuracy: 0.6463\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 536s 4s/step - loss: 1.2300 - accuracy: 0.5551 - val_loss: 0.9922 - val_accuracy: 0.6741\n",
            "Epoch 9/20\n",
            "148/148 [==============================] - 503s 3s/step - loss: 1.1809 - accuracy: 0.5719 - val_loss: 0.9365 - val_accuracy: 0.6841\n",
            "Epoch 10/20\n",
            "148/148 [==============================] - 507s 3s/step - loss: 1.1222 - accuracy: 0.5968 - val_loss: 0.8946 - val_accuracy: 0.7174\n",
            "Epoch 11/20\n",
            "148/148 [==============================] - 554s 4s/step - loss: 1.0781 - accuracy: 0.6135 - val_loss: 0.9728 - val_accuracy: 0.6652\n",
            "Epoch 12/20\n",
            "148/148 [==============================] - 606s 4s/step - loss: 1.0273 - accuracy: 0.6298 - val_loss: 0.8342 - val_accuracy: 0.7185\n",
            "Epoch 13/20\n",
            "148/148 [==============================] - 572s 4s/step - loss: 0.9910 - accuracy: 0.6461 - val_loss: 0.8403 - val_accuracy: 0.7022\n",
            "Epoch 14/20\n",
            "148/148 [==============================] - 496s 3s/step - loss: 0.9381 - accuracy: 0.6638 - val_loss: 0.7685 - val_accuracy: 0.7493\n",
            "Epoch 15/20\n",
            "148/148 [==============================] - 505s 3s/step - loss: 0.9261 - accuracy: 0.6722 - val_loss: 0.7644 - val_accuracy: 0.7448\n",
            "Epoch 16/20\n",
            "148/148 [==============================] - 481s 3s/step - loss: 0.8680 - accuracy: 0.6907 - val_loss: 0.7356 - val_accuracy: 0.7611\n",
            "Epoch 17/20\n",
            "148/148 [==============================] - 496s 3s/step - loss: 0.8666 - accuracy: 0.6947 - val_loss: 0.7464 - val_accuracy: 0.7556\n",
            "Epoch 18/20\n",
            "148/148 [==============================] - 475s 3s/step - loss: 0.8222 - accuracy: 0.7078 - val_loss: 0.7817 - val_accuracy: 0.7344\n",
            "Epoch 00018: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_nine_history = model_nine.fit(train_generator, \n",
        "                                  epochs= 20, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAkqgCw_AzGB",
        "outputId": "c8116956-2c74-456c-eda7-c0c3d0639cb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 41s 961ms/step - loss: 0.7606 - accuracy: 0.7452\n",
            "Test loss:  0.760615348815918\n",
            "Test accuracy:  0.7451851963996887\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_nine.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DABtFT_oAzGB"
      },
      "source": [
        "### Model 10- Add Dense (16) and 0.2 Dropout Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTs6jFD-AzGC"
      },
      "source": [
        "Also increased number of Epochs to 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtcrN6XiAzGC",
        "outputId": "fbd4583d-7677-44e1-ecb7-68f62508fb69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 60, 60, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 28800)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 64)                1843264   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 1,865,434\n",
            "Trainable params: 1,865,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_ten = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_ten.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3)))\n",
        "\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_ten.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_ten.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_ten.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- another convolution layer \n",
        "model_ten.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 5- another max pool layer\n",
        "model_ten.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 6- connect all nodes with dense layer\n",
        "model_ten.add(Flatten())\n",
        "model_ten.add(Dense(64, activation='relu'))\n",
        "model_ten.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 7- dense layer\n",
        "model_ten.add(Dense(32, activation='relu'))\n",
        "model_ten.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 7- dense layer\n",
        "model_ten.add(Dense(16, activation='relu'))\n",
        "model_ten.add(layers.Dropout(0.2))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_ten.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_ten.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_ten.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEnJDx4kAzGC",
        "outputId": "652a50b2-2afd-4b0c-bfbc-784dca6f1eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "148/148 [==============================] - 622s 4s/step - loss: 2.0001 - accuracy: 0.2441 - val_loss: 1.4877 - val_accuracy: 0.4644\n",
            "Epoch 2/50\n",
            "148/148 [==============================] - 544s 4s/step - loss: 1.5896 - accuracy: 0.3908 - val_loss: 1.2697 - val_accuracy: 0.5296\n",
            "Epoch 3/50\n",
            "148/148 [==============================] - 521s 4s/step - loss: 1.4313 - accuracy: 0.4567 - val_loss: 1.2073 - val_accuracy: 0.5552\n",
            "Epoch 4/50\n",
            "148/148 [==============================] - 520s 4s/step - loss: 1.3009 - accuracy: 0.5120 - val_loss: 1.0292 - val_accuracy: 0.6367\n",
            "Epoch 5/50\n",
            "148/148 [==============================] - 519s 4s/step - loss: 1.1568 - accuracy: 0.5681 - val_loss: 0.9088 - val_accuracy: 0.6719\n",
            "Epoch 6/50\n",
            "148/148 [==============================] - 528s 4s/step - loss: 1.0614 - accuracy: 0.6100 - val_loss: 0.8606 - val_accuracy: 0.7063\n",
            "Epoch 7/50\n",
            "148/148 [==============================] - 522s 4s/step - loss: 0.9663 - accuracy: 0.6494 - val_loss: 0.8364 - val_accuracy: 0.6933\n",
            "Epoch 8/50\n",
            "148/148 [==============================] - 487s 3s/step - loss: 0.9072 - accuracy: 0.6733 - val_loss: 0.8075 - val_accuracy: 0.7385\n",
            "Epoch 9/50\n",
            "148/148 [==============================] - 498s 3s/step - loss: 0.8207 - accuracy: 0.7096 - val_loss: 0.7680 - val_accuracy: 0.7463\n",
            "Epoch 10/50\n",
            "148/148 [==============================] - 509s 3s/step - loss: 0.7634 - accuracy: 0.7321 - val_loss: 0.7371 - val_accuracy: 0.7604\n",
            "Epoch 11/50\n",
            "148/148 [==============================] - 456s 3s/step - loss: 0.7232 - accuracy: 0.7505 - val_loss: 0.7084 - val_accuracy: 0.7767\n",
            "Epoch 12/50\n",
            "148/148 [==============================] - 485s 3s/step - loss: 0.6728 - accuracy: 0.7715 - val_loss: 0.7213 - val_accuracy: 0.7663\n",
            "Epoch 13/50\n",
            "148/148 [==============================] - 577s 4s/step - loss: 0.6131 - accuracy: 0.7892 - val_loss: 0.7271 - val_accuracy: 0.7567\n",
            "Epoch 00013: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_ten_history = model_ten.fit(train_generator, \n",
        "                                  epochs= 50, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dEuaRbqAzGC",
        "outputId": "acd702e1-dafa-4418-ad4f-dc488e5ff6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 36s 839ms/step - loss: 0.7133 - accuracy: 0.7635\n",
            "Test loss:  0.7133249044418335\n",
            "Test accuracy:  0.7635185122489929\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_ten.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkECx578AzGC"
      },
      "source": [
        "### Model 11- Wider CNN with 0.2 Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB1G-XD7AzGD",
        "outputId": "9d27ef5a-b327-4829-a694-943eeb270d86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 60, 60, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 28800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               14746112  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 14,905,386\n",
            "Trainable params: 14,905,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_eleven = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_eleven.add(Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3)))\n",
        "\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_eleven.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_eleven.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_eleven.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- another convolution layer \n",
        "model_eleven.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 5- another max pool layer\n",
        "model_eleven.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 6- connect all nodes with dense layer\n",
        "model_eleven.add(Flatten())\n",
        "model_eleven.add(Dense(512, activation='relu'))\n",
        "model_eleven.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 7- dense layer\n",
        "model_eleven.add(Dense(256, activation='relu'))\n",
        "model_eleven.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 7- dense layer\n",
        "model_eleven.add(Dense(32, activation='relu'))\n",
        "model_eleven.add(layers.Dropout(0.2))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_eleven.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_eleven.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_eleven.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s8QFs45AzGD",
        "outputId": "ffc9ad88-29a0-4188-b890-4c04f9c047d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "148/148 [==============================] - 481s 3s/step - loss: 1.8579 - accuracy: 0.2936 - val_loss: 1.3696 - val_accuracy: 0.5048\n",
            "Epoch 2/50\n",
            "148/148 [==============================] - 473s 3s/step - loss: 1.3091 - accuracy: 0.5207 - val_loss: 0.9868 - val_accuracy: 0.6448\n",
            "Epoch 3/50\n",
            "148/148 [==============================] - 472s 3s/step - loss: 1.0152 - accuracy: 0.6411 - val_loss: 0.7357 - val_accuracy: 0.7396\n",
            "Epoch 4/50\n",
            "148/148 [==============================] - 473s 3s/step - loss: 0.8238 - accuracy: 0.7134 - val_loss: 0.7913 - val_accuracy: 0.7152\n",
            "Epoch 5/50\n",
            "148/148 [==============================] - 474s 3s/step - loss: 0.7157 - accuracy: 0.7537 - val_loss: 0.6792 - val_accuracy: 0.7663\n",
            "Epoch 6/50\n",
            "148/148 [==============================] - 474s 3s/step - loss: 0.5819 - accuracy: 0.8019 - val_loss: 0.6211 - val_accuracy: 0.7774\n",
            "Epoch 7/50\n",
            "148/148 [==============================] - 473s 3s/step - loss: 0.4969 - accuracy: 0.8327 - val_loss: 0.5706 - val_accuracy: 0.8015\n",
            "Epoch 8/50\n",
            "148/148 [==============================] - 476s 3s/step - loss: 0.4347 - accuracy: 0.8554 - val_loss: 0.6551 - val_accuracy: 0.7941\n",
            "Epoch 9/50\n",
            "148/148 [==============================] - 476s 3s/step - loss: 0.3379 - accuracy: 0.8905 - val_loss: 0.7957 - val_accuracy: 0.7400\n",
            "Epoch 00009: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_eleven_history = model_eleven.fit(train_generator, \n",
        "                                  epochs= 50, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xosvYvU7AzGD",
        "outputId": "fcb2671d-bf78-479d-990b-8f61188e4050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 35s 810ms/step - loss: 0.7885 - accuracy: 0.7443\n",
            "Test loss:  0.7884544134140015\n",
            "Test accuracy:  0.744259238243103\n"
          ]
        }
      ],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_eleven.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Larger Models in Google Colab"
      ],
      "metadata": {
        "id": "lpz05K2IBTHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next few models are quite large so we may be best served opening and running them in Google Colab."
      ],
      "metadata": {
        "id": "ZzaB4iO5BOi1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut1t7hp9AzFp"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github//aokdata/Land_Cover_Classification/blob/main/Land_Cover_Classification_Notebook.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aq_S-xdBjIz",
        "outputId": "b3c3d443-0933-4d64-bb2c-bbea5de61882"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlfsBAa8AzGD"
      },
      "source": [
        "### Model 12- Decreasing filter size over 4 Conv2D Layers and 5 Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Data from Google Drive to use in Google Colab\n",
        "train_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/train'\n",
        "test_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/test'\n",
        "\n",
        "# Normalize images\n",
        "train_gen = ImageDataGenerator(rescale=1./255, validation_split = 0.125)\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
        "train_generator = train_gen.flow_from_directory(train_folder,\n",
        "                                                class_mode = 'categorical', \n",
        "                                                subset ='training', \n",
        "                                                batch_size=128,\n",
        "                                                shuffle=True,\n",
        "                                                seed=42)\n",
        "                                               \n",
        "val_generator= train_gen.flow_from_directory(train_folder,\n",
        "                                             class_mode= 'categorical',\n",
        "                                             subset = \"validation\",\n",
        "                                             batch_size=128,\n",
        "                                             shuffle=True,\n",
        "                                             seed=42)\n",
        "\n",
        "test_generator= test_gen.flow_from_directory(test_folder,\n",
        "                                              class_mode= 'categorical',\n",
        "                                              batch_size=128,\n",
        "                                              shuffle=False,\n",
        "                                              seed=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWXCLV6zC0P3",
        "outputId": "8ee1ecd1-d0d6-4044-f82e-846f92a553ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18909 images belonging to 10 classes.\n",
            "Found 2701 images belonging to 10 classes.\n",
            "Found 5400 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "JnkiQSqlAzGE",
        "outputId": "b3c2cbc2-c3b7-4e40-e586-1959bfb60054"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-15fdf1d4e807>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Instantiate a Sequential model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_twelve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Input Layer- Convolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ],
      "source": [
        "#Instantiate a Sequential model\n",
        "model_twelve = Sequential()\n",
        "\n",
        "\n",
        "# Input Layer- Convolution\n",
        "model_twelve.add(Conv2D(filters=128,\n",
        "                          kernel_size=(3, 3),\n",
        "                          activation='relu',\n",
        "                          input_shape= (256, 256, 3)))\n",
        "\n",
        "\n",
        "# Layer 1- max pool in 2x2 window\n",
        "model_twelve.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2- another convolution layer \n",
        "model_twelve.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 3- another max pool layer\n",
        "model_twelve.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 4- another convolution layer \n",
        "model_twelve.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 5- another max pool layer\n",
        "model_twelve.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 6- another convolution layer \n",
        "model_twelve.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "\n",
        "# Layer 7- another max pool layer\n",
        "model_twelve.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer 8- connect all nodes with dense layer\n",
        "model_twelve.add(Flatten())\n",
        "model_twelve.add(Dense(512, activation='relu'))\n",
        "model_twelve.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 9- dense layer\n",
        "model_twelve.add(Dense(256, activation='relu'))\n",
        "model_twelve.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 10- dense layer\n",
        "model_twelve.add(Dense(128, activation='relu'))\n",
        "model_twelve.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 11- dense layer\n",
        "model_twelve.add(Dense(32, activation='relu'))\n",
        "model_twelve.add(layers.Dropout(0.2))\n",
        "\n",
        "# Layer 12- dense layer\n",
        "model_twelve.add(Dense(16, activation='relu'))\n",
        "model_twelve.add(layers.Dropout(0.2))\n",
        "\n",
        "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
        "model_twelve.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the sequential CNN model- adam optimizer, \n",
        "# categorical_crossentropy loss, and set our metric to accuracy\n",
        "model_twelve.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model_twelve.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2qfUYAAAzGE"
      },
      "outputs": [],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_twelve_history = model_twelve.fit(train_generator, \n",
        "                                  epochs= 50, \n",
        "                                  validation_data = val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku1QqDIdAzGE"
      },
      "outputs": [],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = model_twelve.evaluate(test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD9MvD2MAzGF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uvv7y-xAzGF"
      },
      "source": [
        "### Model 13- Transfer Learning: ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0kvNWH-AzGF"
      },
      "outputs": [],
      "source": [
        "train_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/train'\n",
        "test_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/test'\n",
        "\n",
        "# Normalize images\n",
        "train_gen = ImageDataGenerator(rescale=1./255, \n",
        "                               preprocessing_function = tf.keras.applications.resnet50.preprocess_input,\n",
        "                               validation_split = 0.125)\n",
        "test_gen = ImageDataGenerator(rescale=1./255, \n",
        "                              preprocessing_function = tf.keras.applications.resnet50.preprocess_input)\n",
        "\n",
        "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
        "rn_train_generator = train_gen.flow_from_directory(train_folder,\n",
        "                                                class_mode = 'categorical', \n",
        "                                                subset ='training', \n",
        "                                                batch_size=128,\n",
        "                                                shuffle=True,\n",
        "                                                seed=42)\n",
        "                                               \n",
        "rn_val_generator= train_gen.flow_from_directory(train_folder,\n",
        "                                             class_mode= 'categorical',\n",
        "                                             subset = \"validation\",\n",
        "                                             batch_size=128,\n",
        "                                             shuffle=True,\n",
        "                                             seed=42)\n",
        "\n",
        "rn_test_generator= test_gen.flow_from_directory(test_folder,\n",
        "                                              class_mode= 'categorical',\n",
        "                                              batch_size=128,\n",
        "                                              shuffle=False,\n",
        "                                              seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6plgek1jAzGF"
      },
      "outputs": [],
      "source": [
        "# Instantiate our Transfer Model Input Layer\n",
        "rn50 = ResNet50(weights='imagenet', \n",
        "                 include_top=False,\n",
        "                input_shape=(256, 256, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoOw-QUuAzGG"
      },
      "outputs": [],
      "source": [
        "#Check to ensure there is no prediction layer\n",
        "rn50.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNhh3jmfAzGG"
      },
      "outputs": [],
      "source": [
        "#Instantiate a Sequential model\n",
        "rn50_model = Sequential()\n",
        "\n",
        "#Input Layer\n",
        "rn50_model.add(rn50)\n",
        "\n",
        "rn50_model.add(layers.Flatten())\n",
        "\n",
        "#Add Dense Layer\n",
        "rn50_model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "#Output Layer\n",
        "rn50_model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VYCAwzwAzGG"
      },
      "outputs": [],
      "source": [
        "# Check whether a layer is trainable (or alter its setting) through the layer.trainable attribute\n",
        "for layer in rn50_model.layers:\n",
        "    print(layer.name, layer.trainable)\n",
        "    \n",
        "# Similarly, you can check how many trainable weights are in the model\n",
        "print(len(rn50_model.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-re4Tc-AzGG"
      },
      "outputs": [],
      "source": [
        "# Freeze our RN50 Layer\n",
        "rn50.trainable = False\n",
        "\n",
        "# Sanity Check that RN50 layer is frozen\n",
        "for layer in rn50_model.layers:\n",
        "    print(layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbHcmiwYAzGG"
      },
      "outputs": [],
      "source": [
        "#Compile the model- adam optimizer, categorical_crossentropy loss, and set our metric to accuracy\n",
        "rn50_model.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "rn50_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EhGd-7bAzGH"
      },
      "outputs": [],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = [EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2), \n",
        "               ModelCheckpoint(filepath='rn50_model.h5', monitor='val_accuracy', save_best_only=True)]\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "rn50_model_history = rn50_model.fit(rn_train_generator, \n",
        "                                  epochs= 50, \n",
        "                                  validation_data = rn_val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yBPiHb-AzGR"
      },
      "outputs": [],
      "source": [
        "#Check loss and accuracy on test data\n",
        "test_loss, test_acc = rn50_model.evaluate(rn_test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti_w0xD2AzGR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mrRj_ZHAzGR"
      },
      "source": [
        "### Model 14- Transfer Learning: VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P5nH1fNAzGS"
      },
      "outputs": [],
      "source": [
        "train_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/train'\n",
        "test_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/test'\n",
        "\n",
        "# Normalize images\n",
        "train_gen = ImageDataGenerator(rescale=1./255, \n",
        "                               preprocessing_function = tf.keras.applications.vgg19.preprocess_input,\n",
        "                               validation_split = 0.125)\n",
        "test_gen = ImageDataGenerator(rescale=1./255, \n",
        "                              preprocessing_function = tf.keras.applications.vgg19.preprocess_input)\n",
        "\n",
        "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
        "vgg_train_generator = train_gen.flow_from_directory(train_folder,\n",
        "                                                class_mode = 'categorical', \n",
        "                                                subset ='training', \n",
        "                                                batch_size=128,\n",
        "                                                shuffle=True,\n",
        "                                                seed=42)\n",
        "                                               \n",
        "vgg_val_generator= train_gen.flow_from_directory(train_folder,\n",
        "                                             class_mode= 'categorical',\n",
        "                                             subset = \"validation\",\n",
        "                                             batch_size=128,\n",
        "                                             shuffle=True,\n",
        "                                             seed=42)\n",
        "\n",
        "vgg_test_generator= test_gen.flow_from_directory(test_folder,\n",
        "                                              class_mode= 'categorical',\n",
        "                                              batch_size=128,\n",
        "                                              shuffle=False,\n",
        "                                              seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aw5iBRHIAzGS"
      },
      "outputs": [],
      "source": [
        "#Reshape our input\n",
        "vgg19 = VGG19(weights='imagenet', \n",
        "              include_top=False, \n",
        "              input_shape=(256, 256, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSpv7I9_AzGS"
      },
      "outputs": [],
      "source": [
        "#Check to ensure there is no prediction layer\n",
        "vgg19.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8ckXMWXAzGS"
      },
      "outputs": [],
      "source": [
        "#Instantiate a Sequential model\n",
        "vgg_model = Sequential()\n",
        "\n",
        "#Input Layer\n",
        "# vgg_model.add(vgg)\n",
        "vgg_model.add(vgg19)\n",
        "\n",
        "vgg_model.add(layers.Flatten())\n",
        "\n",
        "#Add Dense Layer\n",
        "vgg_model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "#Output Layer\n",
        "vgg_model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9AodJqpAzGW"
      },
      "outputs": [],
      "source": [
        "# Check whether a layer is trainable (or alter its setting) through the layer.trainable attribute\n",
        "for layer in vgg_model.layers:\n",
        "    print(layer.name, layer.trainable)\n",
        "    \n",
        "# Similarly, you can check how many trainable weights are in the model\n",
        "print(len(vgg_model.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f47SHT_AzGW"
      },
      "outputs": [],
      "source": [
        "#Freeze our VGG19 Layer\n",
        "vgg19.trainable = False\n",
        "\n",
        "#Sanity check that VGG19 Layer is frozen\n",
        "for layer in vgg_model.layers:\n",
        "    print(layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu-RT8bkAzGW"
      },
      "outputs": [],
      "source": [
        "#Compile the model- adam optimizer, categorical_crossentropy loss, and set our metric to accuracy\n",
        "vgg_model.compile(optimizer='adam', \n",
        "                       loss='categorical_crossentropy',  \n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "vgg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDvg4dSOAzGW"
      },
      "outputs": [],
      "source": [
        "# Define Stopping Criteria \n",
        "valcallback = [EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2), \n",
        "               ModelCheckpoint(filepath='vgg19_model.h5', monitor='val_accuracy', save_best_only=True)]\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "vgg_model_history = vgg_model.fit(vgg_train_generator, \n",
        "                                  epochs= 50, \n",
        "                                  validation_data = vgg_val_generator, \n",
        "                                  callbacks= valcallback, \n",
        "                                  batch_size=128, \n",
        "                                  verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee2jpdBPAzGa"
      },
      "outputs": [],
      "source": [
        "# Check loss and accuracy on test data\n",
        "test_loss, test_acc = vgg_model.evaluate(vgg_test_generator, verbose = 1)\n",
        "\n",
        "print('Test loss: ', test_loss)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K25_JB9MAzGb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIMO5epEAzGb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QimTGtyCAzGb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8sP-WjzAzGb"
      },
      "outputs": [],
      "source": [
        "# Add augmentation (horizontal flip) to training data but not validation data.\n",
        "\n",
        "# train_folder = 'data/split/train'\n",
        "\n",
        "# # Normalize images and Augment with Horizontal Flip\n",
        "# aug_train_gen = ImageDataGenerator(rescale=1./255, \n",
        "#                                horizontal_flip=True,\n",
        "#                                validation_split = 0.125)\n",
        "\n",
        "# #Augment the train data\n",
        "# aug_train_generator = aug_train_gen.flow_from_directory(train_folder,\n",
        "#                                                 class_mode = 'categorical', \n",
        "#                                                 subset ='training', \n",
        "#                                                 batch_size=128,\n",
        "#                                                 shuffle=False,\n",
        "#                                                 seed=42)\n",
        "                                               \n",
        "# aug_val_generator= ImageDataGenerator(rescale=1./255,\n",
        "#                                validation_split = 0.125).flow_from_directory(train_folder,\n",
        "#                                              class_mode= 'categorical',\n",
        "#                                              subset = \"validation\",\n",
        "#                                              batch_size=128,\n",
        "#                                              shuffle=False,\n",
        "#                                              seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt2sANR5AzGb"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EltIRwLAAzGb"
      },
      "source": [
        "Compared to my Baseline Model's performance of 74.1% Test accuracy, my final model was Model 8 with a 78.01% Test accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2iIoxXrAzGb"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KptBbdkcAzGb"
      },
      "source": [
        "### Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eisyP48jAzGb"
      },
      "source": [
        "- Use this land cover classifier tool on images of the same land area over time.\n",
        "- Focus deforestation prevention efforts on known wildlife corridor areas where an imageâ€™s class has changed over time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_-biIrAzGc"
      },
      "source": [
        "### Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf1nBjxCAzGc"
      },
      "source": [
        "Create object detection to help classify multiple areas of land cover within an image. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32ZvJbltAzGc"
      },
      "source": [
        "### References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOPDOPMEAzGc"
      },
      "source": [
        "[1] Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. Patrick Helber, Benjamin Bischke, Andreas Dengel, Damian Borth. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26AxyM_xAzGc"
      },
      "source": [
        "[2] Introducing EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification. Patrick Helber, Benjamin Bischke, Andreas Dengel. 2018 IEEE International Geoscience and Remote Sensing Symposium, 2018."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEuxSFHMAzGc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (learn-env)",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}