{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Cover Classification of Satellite Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aidan O'Keefe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deep learning (neural network) land cover classification project using satellite images (remote sensing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed libraries\n",
    "import os, shutil\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "#Standard Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizations\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "\n",
    "from tensorflow.data.experimental import cardinality\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense # creates densely connected layer object\n",
    "from tensorflow.keras.layers import Flatten # takes 2D input and turns into 1D array\n",
    "from tensorflow.keras.layers import Conv2D # convolution layer\n",
    "from tensorflow.keras.layers import MaxPooling2D # max pooling layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Images into Train and Test folders using OS and Shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List image path for all categories\n",
    "data_AnnualCrop = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/AnnualCrop'\n",
    "data_Forest = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Forest'\n",
    "data_HerbaceousVegetation = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/HerbaceousVegetation'\n",
    "data_Highway = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Highway'\n",
    "data_Industrial = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Industrial'\n",
    "data_Pasture = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Pasture'\n",
    "data_PermanentCrop = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/PermanentCrop'\n",
    "data_Residential = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Residential'\n",
    "data_River = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/River'\n",
    "data_SeaLake = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/SeaLake'\n",
    "\n",
    "\n",
    "new_dir = 'data/split/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create objects that store all the relevant image names.\n",
    "imgs_AnnualCrop = [file for file in os.listdir(data_AnnualCrop) if file.endswith('.jpg')]\n",
    "imgs_Forest = [file for file in os.listdir(data_Forest) if file.endswith('.jpg')]\n",
    "imgs_HerbaceousVegetation = [file for file in os.listdir(data_HerbaceousVegetation) if file.endswith('.jpg')]\n",
    "imgs_Highway = [file for file in os.listdir(data_Highway) if file.endswith('.jpg')]\n",
    "imgs_Industrial = [file for file in os.listdir(data_Industrial) if file.endswith('.jpg')]\n",
    "imgs_Pasture = [file for file in os.listdir(data_Pasture) if file.endswith('.jpg')]\n",
    "imgs_PermanentCrop = [file for file in os.listdir(data_PermanentCrop) if file.endswith('.jpg')]\n",
    "imgs_Residential = [file for file in os.listdir(data_Residential) if file.endswith('.jpg')]\n",
    "imgs_River = [file for file in os.listdir(data_River) if file.endswith('.jpg')]\n",
    "imgs_SeaLake = [file for file in os.listdir(data_SeaLake) if file.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new split folder\n",
    "os.mkdir(new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the Train folder and subfolders\n",
    "train_folder = os.path.join(new_dir, 'train')\n",
    "train_AnnualCrop = os.path.join(train_folder, 'AnnualCrop')\n",
    "train_Forest = os.path.join(train_folder, 'Forest')\n",
    "train_HerbaceousVegetation = os.path.join(train_folder, 'HerbaceousVegetation')\n",
    "train_Highway = os.path.join(train_folder, 'Highway')\n",
    "train_Industrial = os.path.join(train_folder, 'Industrial')\n",
    "train_Pasture = os.path.join(train_folder, 'Pasture')\n",
    "train_PermanentCrop = os.path.join(train_folder, 'PermanentCrop')\n",
    "train_Residential = os.path.join(train_folder, 'Residential')\n",
    "train_River = os.path.join(train_folder, 'River')\n",
    "train_SeaLake = os.path.join(train_folder, 'SeaLake')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the Test folder and subfolders\n",
    "test_folder = os.path.join(new_dir, 'test')\n",
    "test_AnnualCrop = os.path.join(test_folder, 'AnnualCrop')\n",
    "test_Forest = os.path.join(test_folder, 'Forest')\n",
    "test_HerbaceousVegetation = os.path.join(test_folder, 'HerbaceousVegetation')\n",
    "test_Highway = os.path.join(test_folder, 'Highway')\n",
    "test_Industrial = os.path.join(test_folder, 'Industrial')\n",
    "test_Pasture = os.path.join(test_folder, 'Pasture')\n",
    "test_PermanentCrop = os.path.join(test_folder, 'PermanentCrop')\n",
    "test_Residential = os.path.join(test_folder, 'Residential')\n",
    "test_River = os.path.join(test_folder, 'River')\n",
    "test_SeaLake = os.path.join(test_folder, 'SeaLake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the Train directories(folders)\n",
    "os.mkdir(train_folder)\n",
    "os.mkdir(train_AnnualCrop)\n",
    "os.mkdir(train_Forest)\n",
    "os.mkdir(train_HerbaceousVegetation)\n",
    "os.mkdir(train_Highway)\n",
    "os.mkdir(train_Industrial)\n",
    "os.mkdir(train_Pasture)\n",
    "os.mkdir(train_PermanentCrop)\n",
    "os.mkdir(train_Residential)\n",
    "os.mkdir(train_River)\n",
    "os.mkdir(train_SeaLake)\n",
    "\n",
    "# Make the Test directories(folders)\n",
    "os.mkdir(test_folder)\n",
    "os.mkdir(test_AnnualCrop)\n",
    "os.mkdir(test_Forest)\n",
    "os.mkdir(test_HerbaceousVegetation)\n",
    "os.mkdir(test_Highway)\n",
    "os.mkdir(test_Industrial)\n",
    "os.mkdir(test_Pasture)\n",
    "os.mkdir(test_PermanentCrop)\n",
    "os.mkdir(test_Residential)\n",
    "os.mkdir(test_River)\n",
    "os.mkdir(test_SeaLake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile 80% of images into folders- Train\n",
    "imgs = imgs_AnnualCrop[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_AnnualCrop, img)\n",
    "    destination = os.path.join(train_AnnualCrop, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Forest[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Forest, img)\n",
    "    destination = os.path.join(train_Forest, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = imgs_HerbaceousVegetation[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_HerbaceousVegetation, img)\n",
    "    destination = os.path.join(train_HerbaceousVegetation, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Highway[:2000]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Highway, img)\n",
    "    destination = os.path.join(train_Highway, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Industrial[:2000]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Industrial, img)\n",
    "    destination = os.path.join(train_Industrial, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Pasture[:1600]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Pasture, img)\n",
    "    destination = os.path.join(train_Pasture, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_PermanentCrop[:2000]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_PermanentCrop, img)\n",
    "    destination = os.path.join(train_PermanentCrop, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Residential[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Residential, img)\n",
    "    destination = os.path.join(train_Residential, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_River[:2000]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_River, img)\n",
    "    destination = os.path.join(train_River, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_SeaLake[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_SeaLake, img)\n",
    "    destination = os.path.join(train_SeaLake, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile other 20% of images into folders- Test\n",
    "imgs = imgs_AnnualCrop[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_AnnualCrop, img)\n",
    "    destination = os.path.join(test_AnnualCrop, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Forest[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Forest, img)\n",
    "    destination = os.path.join(test_Forest, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = imgs_HerbaceousVegetation[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_HerbaceousVegetation, img)\n",
    "    destination = os.path.join(test_HerbaceousVegetation, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Highway[2000:] #500\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Highway, img)\n",
    "    destination = os.path.join(test_Highway, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Industrial[2000:] #500\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Industrial, img)\n",
    "    destination = os.path.join(test_Industrial, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Pasture[1600:] #400\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Pasture, img)\n",
    "    destination = os.path.join(test_Pasture, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_PermanentCrop[2000:] #500\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_PermanentCrop, img)\n",
    "    destination = os.path.join(test_PermanentCrop, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Residential[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Residential, img)\n",
    "    destination = os.path.join(test_Residential, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_River[2000:] #500\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_River, img)\n",
    "    destination = os.path.join(test_River, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_SeaLake[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_SeaLake, img)\n",
    "    destination = os.path.join(test_SeaLake, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18900 images belonging to 10 classes.\n",
      "Found 2700 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_folder = 'data/split/train'\n",
    "test_folder = 'data/split/test'\n",
    "\n",
    "# Normalize images\n",
    "train_gen = ImageDataGenerator(rescale=1./255, validation_split = 0.125)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
    "train_generator = train_gen.flow_from_directory(train_folder,\n",
    "                                                class_mode = 'categorical', \n",
    "                                                subset ='training', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True,\n",
    "                                                seed=42)\n",
    "                                               \n",
    "val_generator= train_gen.flow_from_directory(train_folder,\n",
    "                                             class_mode= 'categorical',\n",
    "                                             subset = \"validation\",\n",
    "                                             batch_size=128,\n",
    "                                             shuffle=True,\n",
    "                                             seed=42)\n",
    "\n",
    "test_generator= test_gen.flow_from_directory(test_folder,\n",
    "                                              class_mode= 'categorical',\n",
    "                                              batch_size=128,\n",
    "                                              shuffle=True,\n",
    "                                              seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data sets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ~ [(0, 2100), (1, 2100), (2, 2100), (3, 1750), (4, 1750), (5, 1400), (6, 1750), (7, 2100), (8, 1750), (9, 2100)]\n",
      "Validation ~ [(0, 300), (1, 300), (2, 300), (3, 250), (4, 250), (5, 200), (6, 250), (7, 300), (8, 250), (9, 300)]\n",
      "Test ~ [(0, 600), (1, 600), (2, 600), (3, 500), (4, 500), (5, 400), (6, 500), (7, 600), (8, 500), (9, 600)]\n"
     ]
    }
   ],
   "source": [
    "#Confirm class balance for train and test\n",
    "train_classes = train_generator.classes\n",
    "val_classes = val_generator.classes\n",
    "test_classes = test_generator.classes\n",
    "\n",
    "train_class, train_count = np.unique(train_classes, return_counts=True)\n",
    "val_class, val_count = np.unique(val_classes, return_counts=True)\n",
    "test_class, test_count = np.unique(test_classes, return_counts=True)\n",
    "\n",
    "print('Train ~ {}'.format(list(zip(train_class, train_count))))\n",
    "print('Validation ~ {}'.format(list(zip(val_class, val_count))))\n",
    "print('Test ~ {}'.format(list(zip(test_class, test_count))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n",
      "Validation: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n",
      "Train: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n"
     ]
    }
   ],
   "source": [
    "#Checking the classes in our train data \n",
    "train_class_names = train_generator.class_indices\n",
    "print('Train:', train_class_names)\n",
    "\n",
    "#Checking the classes in our validation data\n",
    "val_class_names = val_generator.class_indices\n",
    "print('Validation:', val_class_names)\n",
    "\n",
    "#Checking the classes in our test data\n",
    "test_class_names = test_generator.class_indices\n",
    "print('Train:', test_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(128, 256, 256, 3)\n",
      "(128, 10)\n",
      "Validation\n",
      "(128, 256, 256, 3)\n",
      "(128, 10)\n",
      "Test\n",
      "(128, 256, 256, 3)\n",
      "(128, 10)\n"
     ]
    }
   ],
   "source": [
    "# Preview the shape of both the images and labels for both the train and test sets (6 objects total)\n",
    "print(\"Train\")\n",
    "print(np.shape(train_images))\n",
    "print(np.shape(train_labels))\n",
    "print(\"Validation\")\n",
    "print(np.shape(val_images))\n",
    "print(np.shape(val_labels))\n",
    "print(\"Test\")\n",
    "print(np.shape(test_images))\n",
    "print(np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256 at 0x7FF692526610>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview an train data image\n",
    "print(train_labels[0])\n",
    "array_to_img(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256 at 0x7FF689F5DA00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview a test data image\n",
    "print(test_labels[0])\n",
    "array_to_img(test_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_train = train_images.shape[0]\n",
    "# num_px = train_images.shape[1]\n",
    "# m_test = test_images.shape[0]\n",
    "# # m_val = val_images.shape[0]\n",
    "\n",
    "# print (\"Number of training samples: \" + str(m_train))\n",
    "# print (\"Number of testing samples: \" + str(m_test))\n",
    "# # print (\"Number of validation samples: \" + str(m_val))\n",
    "# print (\"train_images shape: \" + str(train_images.shape))\n",
    "# print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "# print (\"test_images shape: \" + str(test_images.shape))\n",
    "# print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "# # print (\"val_images shape: \" + str(val_images.shape))\n",
    "# # print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "# test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "# # val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "# print(train_img.shape)\n",
    "# print(test_img.shape)\n",
    "# # print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = np.reshape(train_labels[:,0], (128,1))\n",
    "# test_y = np.reshape(test_labels[:,0], (128,1))\n",
    "# # val_y = np.reshape(val_labels[:,0], (200,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 516128)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                33032256  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 33,033,802\n",
      "Trainable params: 33,033,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "baseline_model = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "baseline_model.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "baseline_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- connect all nodes with dense layer\n",
    "baseline_model.add(Flatten())\n",
    "baseline_model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "baseline_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "baseline_model.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "148/148 [==============================] - 299s 2s/step - loss: 3.1271 - accuracy: 0.2569 - val_loss: 1.6714 - val_accuracy: 0.3674\n",
      "Epoch 2/5\n",
      "148/148 [==============================] - 287s 2s/step - loss: 1.5236 - accuracy: 0.4086 - val_loss: 1.4423 - val_accuracy: 0.4456\n",
      "Epoch 3/5\n",
      "148/148 [==============================] - 289s 2s/step - loss: 1.3551 - accuracy: 0.4741 - val_loss: 1.3214 - val_accuracy: 0.4785\n",
      "Epoch 4/5\n",
      "148/148 [==============================] - 288s 2s/step - loss: 1.2343 - accuracy: 0.5362 - val_loss: 1.1967 - val_accuracy: 0.5615\n",
      "Epoch 5/5\n",
      "148/148 [==============================] - 289s 2s/step - loss: 1.1562 - accuracy: 0.5709 - val_loss: 1.1298 - val_accuracy: 0.5796\n"
     ]
    }
   ],
   "source": [
    "#Fit the model \n",
    "baseline_history = baseline_model.fit(train_generator, \n",
    "                                      epochs = 20, \n",
    "                                      batch_size= 128, \n",
    "                                      verbose = 1, \n",
    "                                      validation_data = val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 25s 586ms/step - loss: 1.1399 - accuracy: 0.5715\n",
      "Test loss:  1.1399195194244385\n",
      "Test accuracy:  0.571481466293335\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = baseline_model.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like after 5 Epochs our baseline model has an train and test accuracy of about 57%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our CNN \"deeper\" and add additonal convolution and max pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 124, 124, 32)      16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,890,538\n",
      "Trainable params: 7,890,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_one = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_one.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_one.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_one.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_one.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_one.add(Flatten())\n",
    "model_one.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_one.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_one.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_one.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also add a stopping criteria as we will be running our models for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 536s 4s/step - loss: 1.9524 - accuracy: 0.2476 - val_loss: 1.7115 - val_accuracy: 0.3044\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 528s 4s/step - loss: 1.6564 - accuracy: 0.3626 - val_loss: 1.5844 - val_accuracy: 0.3937\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 528s 4s/step - loss: 1.5618 - accuracy: 0.4071 - val_loss: 1.5368 - val_accuracy: 0.4019\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 524s 4s/step - loss: 1.5130 - accuracy: 0.4306 - val_loss: 1.4690 - val_accuracy: 0.4641\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 526s 4s/step - loss: 1.3927 - accuracy: 0.4829 - val_loss: 1.3521 - val_accuracy: 0.4941\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 528s 4s/step - loss: 1.1429 - accuracy: 0.5815 - val_loss: 1.4810 - val_accuracy: 0.4415\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 527s 4s/step - loss: 1.0788 - accuracy: 0.6037 - val_loss: 1.1528 - val_accuracy: 0.5700\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 528s 4s/step - loss: 0.9122 - accuracy: 0.6759 - val_loss: 1.1891 - val_accuracy: 0.5907\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 527s 4s/step - loss: 0.8263 - accuracy: 0.7072 - val_loss: 1.1081 - val_accuracy: 0.6337\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 525s 4s/step - loss: 0.6983 - accuracy: 0.7565 - val_loss: 1.0155 - val_accuracy: 0.6563\n",
      "Epoch 11/20\n",
      "148/148 [==============================] - 526s 4s/step - loss: 0.6571 - accuracy: 0.7733 - val_loss: 1.0042 - val_accuracy: 0.6537\n",
      "Epoch 12/20\n",
      "148/148 [==============================] - 525s 4s/step - loss: 0.5504 - accuracy: 0.8158 - val_loss: 1.0047 - val_accuracy: 0.6711\n",
      "Epoch 13/20\n",
      "148/148 [==============================] - 527s 4s/step - loss: 0.4573 - accuracy: 0.8521 - val_loss: 1.1646 - val_accuracy: 0.6370\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_one_history = model_one.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 41s 956ms/step - loss: 1.1719 - accuracy: 0.6444\n",
      "Test loss:  1.1719359159469604\n",
      "Test accuracy:  0.644444465637207\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_one.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # probability for each class\n",
    "# y_proba = model_images.predict(x_test)\n",
    "# y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # argmax axis = -1 gets the column index of maximum probability for each row.\n",
    "# # column index corresponds to digit classes (numbers 0 -9)\n",
    "# predicted = np.argmax(y_proba, axis=-1)\n",
    "# predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #View confusion matrix of test predictions\n",
    "# cm_digits = confusion_matrix(y_test, predicted)\n",
    "# disp = ConfusionMatrixDisplay(\n",
    "#     confusion_matrix=cm_digits)\n",
    "\n",
    "# disp.plot(cmap=plt.cm.Blues)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2- L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 124, 124, 32)      16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,890,538\n",
      "Trainable params: 7,890,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_l1 = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_l1.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3),\n",
    "                     kernel_regularizer=regularizers.l1(0.005)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_l1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_l1.add(layers.Conv2D(32, (4, 4), \n",
    "                            activation='relu', \n",
    "                            kernel_regularizer=regularizers.l1(0.005)))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_l1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_l1.add(Flatten())\n",
    "model_l1.add(Dense(64, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=regularizers.l1(0.005)))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_l1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_l1.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_l1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 542s 4s/step - loss: 13.3760 - accuracy: 0.2088 - val_loss: 7.1874 - val_accuracy: 0.2570\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 532s 4s/step - loss: 7.0548 - accuracy: 0.2457 - val_loss: 6.8582 - val_accuracy: 0.2189\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 530s 4s/step - loss: 6.8965 - accuracy: 0.2613 - val_loss: 6.8073 - val_accuracy: 0.2685\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 531s 4s/step - loss: 6.8014 - accuracy: 0.2686 - val_loss: 6.6862 - val_accuracy: 0.3000\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 528s 4s/step - loss: 6.7419 - accuracy: 0.2755 - val_loss: 6.8024 - val_accuracy: 0.2541\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 527s 4s/step - loss: 6.7181 - accuracy: 0.2845 - val_loss: 6.6655 - val_accuracy: 0.2967\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 528s 4s/step - loss: 6.6928 - accuracy: 0.2844 - val_loss: 6.6423 - val_accuracy: 0.2793\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 527s 4s/step - loss: 6.6213 - accuracy: 0.2959 - val_loss: 6.5966 - val_accuracy: 0.2911\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 535s 4s/step - loss: 6.6048 - accuracy: 0.3011 - val_loss: 6.5272 - val_accuracy: 0.3115\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 527s 4s/step - loss: 6.5823 - accuracy: 0.3016 - val_loss: 6.5718 - val_accuracy: 0.3081\n",
      "Epoch 11/20\n",
      "148/148 [==============================] - 528s 4s/step - loss: 6.5770 - accuracy: 0.3020 - val_loss: 6.5932 - val_accuracy: 0.2944\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_l1_history = model_l1.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 38s 883ms/step - loss: 6.5853 - accuracy: 0.3015\n",
      "Test loss:  6.585337162017822\n",
      "Test accuracy:  0.3014814853668213\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_l1.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3- L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 124, 124, 32)      16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,890,538\n",
      "Trainable params: 7,890,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_l2 = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_l2.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3),\n",
    "                     kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_l2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_l2.add(layers.Conv2D(32, (4, 4), \n",
    "                            activation='relu', \n",
    "                            kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_l2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_l2.add(Flatten())\n",
    "model_l2.add(Dense(64, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_l2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_l2.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_l2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 529s 4s/step - loss: 2.2535 - accuracy: 0.3123 - val_loss: 1.7472 - val_accuracy: 0.4378\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 529s 4s/step - loss: 1.7020 - accuracy: 0.4045 - val_loss: 1.6228 - val_accuracy: 0.4256\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 529s 4s/step - loss: 1.5932 - accuracy: 0.4484 - val_loss: 1.5801 - val_accuracy: 0.4285\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 529s 4s/step - loss: 1.5286 - accuracy: 0.4637 - val_loss: 1.4975 - val_accuracy: 0.5259\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 531s 4s/step - loss: 1.4671 - accuracy: 0.4776 - val_loss: 1.4665 - val_accuracy: 0.4781\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 529s 4s/step - loss: 1.4333 - accuracy: 0.4935 - val_loss: 1.4403 - val_accuracy: 0.4711\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 530s 4s/step - loss: 1.4069 - accuracy: 0.5130 - val_loss: 1.4653 - val_accuracy: 0.5004\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 530s 4s/step - loss: 1.3662 - accuracy: 0.5352 - val_loss: 1.3629 - val_accuracy: 0.5404\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 529s 4s/step - loss: 1.3182 - accuracy: 0.5699 - val_loss: 1.3971 - val_accuracy: 0.5648\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 531s 4s/step - loss: 1.2755 - accuracy: 0.5864 - val_loss: 1.3527 - val_accuracy: 0.5622\n",
      "Epoch 11/20\n",
      "148/148 [==============================] - 529s 4s/step - loss: 1.2415 - accuracy: 0.6038 - val_loss: 1.3201 - val_accuracy: 0.5259\n",
      "Epoch 12/20\n",
      "148/148 [==============================] - 529s 4s/step - loss: 1.2575 - accuracy: 0.5928 - val_loss: 1.2889 - val_accuracy: 0.5826\n",
      "Epoch 13/20\n",
      "148/148 [==============================] - 530s 4s/step - loss: 1.2065 - accuracy: 0.6232 - val_loss: 1.2411 - val_accuracy: 0.6011\n",
      "Epoch 14/20\n",
      "148/148 [==============================] - 531s 4s/step - loss: 1.1755 - accuracy: 0.6288 - val_loss: 1.2209 - val_accuracy: 0.5967\n",
      "Epoch 15/20\n",
      "148/148 [==============================] - 531s 4s/step - loss: 1.1678 - accuracy: 0.6376 - val_loss: 1.1768 - val_accuracy: 0.6041\n",
      "Epoch 16/20\n",
      "148/148 [==============================] - 530s 4s/step - loss: 1.1393 - accuracy: 0.6425 - val_loss: 1.2560 - val_accuracy: 0.5985\n",
      "Epoch 17/20\n",
      "148/148 [==============================] - 532s 4s/step - loss: 1.1220 - accuracy: 0.6538 - val_loss: 1.1658 - val_accuracy: 0.6407\n",
      "Epoch 18/20\n",
      "148/148 [==============================] - 527s 4s/step - loss: 1.1220 - accuracy: 0.6477 - val_loss: 1.1379 - val_accuracy: 0.6356\n",
      "Epoch 19/20\n",
      "148/148 [==============================] - 527s 4s/step - loss: 1.0813 - accuracy: 0.6653 - val_loss: 1.1368 - val_accuracy: 0.6296\n",
      "Epoch 20/20\n",
      "148/148 [==============================] - 526s 4s/step - loss: 1.1007 - accuracy: 0.6537 - val_loss: 1.1140 - val_accuracy: 0.6563\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_l2_history = model_l2.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 38s 888ms/step - loss: 1.0962 - accuracy: 0.6648\n",
      "Test loss:  1.0961918830871582\n",
      "Test accuracy:  0.664814829826355\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_l2.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4- Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_8 (Dropout)          (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 124, 124, 32)      16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,890,538\n",
      "Trainable params: 7,890,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_dropout = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Dropout\n",
    "model_dropout.add(layers.Dropout(0.3, input_shape= (256, 256, 3)))\n",
    "\n",
    "#Convolution Layer\n",
    "model_dropout.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu'))\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_dropout.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_dropout.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_dropout.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_dropout.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_dropout.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_dropout.add(Flatten())\n",
    "model_dropout.add(Dense(64, activation='relu'))\n",
    "\n",
    "model_dropout.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_dropout.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_dropout.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 609s 4s/step - loss: 2.6446 - accuracy: 0.1148 - val_loss: 2.2975 - val_accuracy: 0.1111\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 608s 4s/step - loss: 2.2962 - accuracy: 0.1124 - val_loss: 2.2952 - val_accuracy: 0.1111\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 611s 4s/step - loss: 2.2955 - accuracy: 0.1103 - val_loss: 2.2949 - val_accuracy: 0.1111\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 608s 4s/step - loss: 2.2952 - accuracy: 0.1119 - val_loss: 2.2948 - val_accuracy: 0.1111\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 607s 4s/step - loss: 2.2950 - accuracy: 0.1100 - val_loss: 2.2948 - val_accuracy: 0.1111\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 608s 4s/step - loss: 2.2952 - accuracy: 0.1113 - val_loss: 2.2948 - val_accuracy: 0.1111\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 610s 4s/step - loss: 2.2952 - accuracy: 0.1118 - val_loss: 2.2948 - val_accuracy: 0.1111\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_dropout_history = model_dropout.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 37s 860ms/step - loss: 2.2948 - accuracy: 0.1111\n",
      "Test loss:  2.294809341430664\n",
      "Test accuracy:  0.1111111119389534\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_dropout.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
